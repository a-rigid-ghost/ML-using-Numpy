{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "data = pd.read_csv('wine.csv')\n",
    "X1 = data.iloc[:,0:11]\n",
    "Y = data.iloc[:,11:12].values\n",
    "\n",
    "iteration=10000\n",
    "\n",
    "X1 = (X1 - X1.min())/(X1.max()-X1.min())\n",
    "X1=X1.values\n",
    "X = np.ones([X1.shape[0],1])\n",
    "X = np.concatenate((X,X1),axis=1)\n",
    "\n",
    "for i in range(1599):\n",
    "    if Y[i,0]<7:\n",
    "        Y[i,0]=0\n",
    "    else:\n",
    "        Y[i,0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypo(X,theta):\n",
    "    Z = np.dot(X, theta)\n",
    "    W=1/(1+np.exp(-Z))\n",
    "    return W\n",
    "\n",
    "def costfunction(X,theta,Y):\n",
    "    Z=hypo(X,theta)\n",
    "    W=-(Y * np.log(Z)) - ((1 - Y) * np.log(1 - Z))\n",
    "    cost= np.sum(W)/(X.shape[0])\n",
    "    return cost\n",
    "\n",
    "def grad_des(X,theta,iteration,Y):\n",
    "        cost = np.zeros(iteration)\n",
    "        for i in range (iteration):\n",
    "            Z = hypo(X,theta)\n",
    "            theta = theta -(0.5)*((X.T).dot((Z-Y)))/(X.shape[0])\n",
    "            cost[i] = costfunction(X,theta,Y)\n",
    "        return theta,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(3, True, 2)\n",
    "sum1=sum2=sum3=0\n",
    "for train, test in kfold.split(X):\n",
    "    X_train=X[train]\n",
    "    Y_train=Y[train]\n",
    "    X_test=X[test]\n",
    "    Y_test=Y[test]\n",
    "    theta=np.zeros([12,1])\n",
    "    theta,cost=grad_des(X_train,theta,iteration,Y_train)\n",
    "    Z=hypo(X_test,theta)\n",
    "    result = (np.where(Z>=0.5,1,0))\n",
    "    sum1=sum1+accuracy_score(Y_test,result)\n",
    "    sum2=sum2+recall_score(Y_test,result)\n",
    "    sum3=sum3+precision_score(Y_test,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8774233896185116\n",
      "Precision = 0.5785714285714286\n",
      "Recall = 0.33583253909421446\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy = '+ str(sum1/3))\n",
    "print('Precision = '+ str(sum3/3))\n",
    "print('Recall = '+ str(sum2/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
